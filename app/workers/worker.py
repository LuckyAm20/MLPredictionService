import io
import json
import logging
import os

import pika
import torch
from database.database import get_session
from models_class.enums import TaskStatus
from models_class.ml_model import MLModel
from models_class.ml_task import MLTask
from models_class.user import User
from PIL import Image
from services.crud.prediction import (update_prediction_result,
                                      update_prediction_status)
from services.crud.user import get_user_by_id, update_user_balance
from torchvision import transforms
from workers.connection import RABBITMQ_HOST, get_rabbitmq_connection

LOG_DIR = os.path.join(os.path.dirname(__file__), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

logging.basicConfig(
    filename=os.path.join(LOG_DIR, "worker.log"),
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)

models = {}
label_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "models", "imagenet-simple-labels.json")
with open(label_path) as f:
    labels = json.load(f)


def load_model(model: str):
    if model not in models:
        model_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "models", f"{model}.pth")
        try:
            models[model] = torch.load(model_path, weights_only=False)
            models[model].eval()
            logging.info(f"–ú–æ–¥–µ–ª—å '{model}' –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.")
        except FileNotFoundError:
            logging.error(f"–ú–æ–¥–µ–ª—å '{model}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
            raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å '{model}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        except Exception as e:
            logging.exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å '{model}': {e}")
            raise e
    return models[model]


transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])


def process_prediction(task_data):
    with next(get_session()) as session:
        try:
            user = get_user_by_id(task_data["user_id"], session)

            with open(task_data["image_path"], "rb") as img_file:
                image_bytes = img_file.read()

            image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
            image = transform(image).unsqueeze(0)

            ml_task = MLTask(
                user=User(user.id, user.username, user.balance),
                id=task_data["task_id"],
                image=image,
                image_path=task_data["image_path"],
                model=MLModel(load_model(task_data["model_name"])),
                cost=task_data["cost"]
            )

            update_prediction_status(task_data["task_id"], TaskStatus.PROCESSING, session)
            ml_task.process_task()

            update_prediction_result(task_data["task_id"], labels[ml_task.result], session)
            update_prediction_status(task_data["task_id"], TaskStatus.COMPLETED, session)

            update_user_balance(user.id, -task_data["cost"], session)

            logging.info(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: ID {task_data['task_id']}, —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {labels[ml_task.result]}")

        except Exception as e:
            logging.exception(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            update_prediction_status(task_data["task_id"], TaskStatus.FAILED, session)


def callback(ch, method, properties, body):
    task_data = json.loads(body)
    logging.info(f"üì© –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: {task_data}")
    process_prediction(task_data)
    ch.basic_ack(delivery_tag=method.delivery_tag)


def start_worker():
    try:
        connection, channel = get_rabbitmq_connection("ml_tasks")
        channel.basic_qos(prefetch_count=1)
        channel.basic_consume(queue="ml_tasks", on_message_callback=callback)

        logging.info("[Worker –∑–∞–ø—É—â–µ–Ω –∏ –æ–∂–∏–¥–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π...")
        channel.start_consuming()

    except Exception as e:
        logging.exception(f"Worker –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {e}")


if __name__ == "__main__":
    start_worker()
